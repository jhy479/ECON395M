---
title: "Problem Set 1"
subtitle: By Jae You (jhy479)
output: md_document
---
``` {r commands, echo=FALSE}

ABIA <- read.csv("https://raw.githubusercontent.com/jgscott/ECO395M/master/data/ABIA.csv")
library(ggplot2)
library(tidyverse)
library(rsample)  # for creating train/test splits
library(caret)
library(modelr)
library(parallel)
library(foreach)
```

1) One interesting observation from the 2008 flight data for Austin-Bergstrom International Airport is the departure time of flights over the course of the week.

```{r ABIA Departure}

ggplot(ABIA)+
  geom_boxplot(aes(group=DayOfWeek, x=DayOfWeek, y=DepTime))+
  xlim(0,7.5)
```

 The boxplots show the Departure Time of the flights across the week, where 1~7 represent the days Monday through Sunday. From the boxplots above, we see that the mean departure time is roughly the same for all the flights except on Saturdays, where the flight departs early. With such a large sample size of almost 100,000 flights, we would expect an even spread across the week, but Saturday's departure time is a clear outlier. However, I came up with a potential explanation for this phenomenon from the graph below.

``` {r ABIA Distance}
library(ggplot2)
ggplot(ABIA)+
  geom_boxplot(aes(group=DayOfWeek, x=DayOfWeek, y=Distance))+
  xlim(0,7.5)
```

 By graphing the distance that flights have to travel across the week, we can see that flights on Saturday have a higher mean distance. So flights would be flying a longer distance than normal on average, which would explain why the flights must depart earlier in order to travel a longer distance and arrive on time.
 
 
 2)
```{r commands2}
 olympics <- read.csv("https://raw.githubusercontent.com/jgscott/ECO395M/master/data/olympics_top20.csv")
```
 
 a)
 
```{r 2A}
olympics %>%
  group_by(sex) %>%
  select(height, sport, event) %>%
  summarize(q95_heights = quantile(height, 0.95))
```

 The 95th percentile of heights for female competitors is 186cm.
 
 b)
 
```{r 2B}
data_olympics =olympics %>%
  filter(sex == "F") %>%
  group_by(event) %>%
  summarize(sdh = sd(height))

head(arrange(data_olympics, desc(sdh)))

```

 The event Rowing Women's Coxed Fours had the greatest standard deviation in female competitor's heights.
 
 c)
 
```{r 2C}
 olympics <- read.csv("https://raw.githubusercontent.com/jgscott/ECO395M/master/data/olympics_top20.csv")

 olympics_swim = olympics %>%
  group_by(year, sex) %>%
  filter(sport == "Swimming") %>%
  summarize(avg_age = mean(age))

 ggplot(olympics_swim)+
  geom_line(aes(x=year, y=avg_age, color=sex))+
  scale_color_brewer(type = "qual")
```
 From the 1930s to now, the average age of Olympic Swimmers has increased over time for both males and females. However, there were only male Olympic Swimmers in 1900 to 1925, where the trend was increasing over time until a sharp drop in the average age around 1925.


 3) 

```{r sclass}
sclass <- read.csv("https://raw.githubusercontent.com/jgscott/ECO395M/master/data/sclass.csv")
```
```{r sclass_trims}
sclass350 = sclass %>%
  filter(trim == 350)

sclass65AMG = sclass %>%
  filter(trim == "65 AMG")
```
 After filtering the two trim levels, I ran KNN for the 350 trim level below:

```{r sclass350_data}

sclass350_split = initial_split(sclass350, prop=0.8)
sclass350_train = training(sclass350_split)
sclass350_test = testing(sclass350_split)

K_folds =5
sclass350_folds = crossv_kfold(sclass350, k=K_folds)


cv_grid350 = foreach(k=2:100, .combine = "rbind") %dopar% {
  models350= map(sclass350_folds$train, ~knnreg(mileage ~ price, k=k, data= ., use.all=FALSE))
  errs350= map2_dbl(models350, sclass350_folds$test, modelr::rmse)
  c(k=k, err=mean(errs350), std_err= sd(errs350)/sqrt(K_folds))
} %>% as.data.frame
  
head(cv_grid350, n=20)  
```

```{r sclass_350 graph}
ggplot(cv_grid350)+
  geom_point(aes(x=k, y=err))
```

 We can see that the lowest rmse is at K=13 for the 350 trim level.
 The fitted model is below:

```{r sclass_350 fitted model}
knn13 = knnreg(mileage ~ price, data=sclass350_train, k=13)
modelr::rmse(knn13, sclass350_test)

sclass350_test = sclass350_test %>%
  mutate(mileage_pred = predict(knn13, sclass350_test))

p_test = ggplot(data=sclass350_test)+
  geom_point(aes(x=price, y=mileage), alpha=0.2)
```

```{r sclass350 graph}
p_test + geom_line(aes(x=price, y=mileage_pred), color="red", linewidth=1.5)
```

 Next, I ran the 65 AMG trim level:
```{r sclass65AMG data} 

sclass65AMG_split = initial_split(sclass65AMG, prop=0.8)
sclass65AMG_train = training(sclass65AMG_split)
sclass65AMG_test = testing(sclass65AMG_split)

K_folds =5
sclass65AMG_folds = crossv_kfold(sclass65AMG, k=K_folds)


cv_grid65AMG = foreach(k=2:100, .combine = "rbind") %dopar% {
  models65AMG= map(sclass65AMG_folds$train, ~knnreg(mileage ~ price, k=k, data= ., use.all=FALSE))
  errs65AMG= map2_dbl(models65AMG, sclass65AMG_folds$test, modelr::rmse)
  c(k=k, err=mean(errs65AMG), std_err= sd(errs65AMG)/sqrt(K_folds))
} %>% as.data.frame

head(cv_grid65AMG, n=20)  
```

```{r sclass_65AMG graph}
ggplot(cv_grid65AMG)+
  geom_point(aes(x=k, y=err))

``` 
 
 We can see that the lowest rmse is at K=18 for the 65AMG trim level.
 The fitted model is below:
 
```{r sclass65AMG fitted model}

knn18 = knnreg(mileage ~ price, data=sclass65AMG_train, k=18)
modelr::rmse(knn18, sclass65AMG_test)

sclass65AMG_test = sclass65AMG_test %>%
  mutate(mileage_pred = predict(knn18, sclass65AMG_test))

p_test2 = ggplot(data=sclass65AMG_test)+
  geom_point(aes(x=price, y=mileage), alpha=0.2)
```

```{r sclass65AMG graph}
p_test2 + geom_line(aes(x=price, y=mileage_pred), color="red", linewidth=1.5)
```
 